[
    {
        "label": "get_supabase_client",
        "importPath": "src.db.session",
        "description": "src.db.session",
        "isExtraImport": true,
        "detail": "src.db.session",
        "documentation": {}
    },
    {
        "label": "insert_user_query",
        "importPath": "src.db.models",
        "description": "src.db.models",
        "isExtraImport": true,
        "detail": "src.db.models",
        "documentation": {}
    },
    {
        "label": "insert_feedback",
        "importPath": "src.db.models",
        "description": "src.db.models",
        "isExtraImport": true,
        "detail": "src.db.models",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timezone",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "bentoml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "bentoml",
        "description": "bentoml",
        "detail": "bentoml",
        "documentation": {}
    },
    {
        "label": "Text",
        "importPath": "bentoml.io",
        "description": "bentoml.io",
        "isExtraImport": true,
        "detail": "bentoml.io",
        "documentation": {}
    },
    {
        "label": "JSON",
        "importPath": "bentoml.io",
        "description": "bentoml.io",
        "isExtraImport": true,
        "detail": "bentoml.io",
        "documentation": {}
    },
    {
        "label": "label_mapping",
        "importPath": "src.utils.label_mapping",
        "description": "src.utils.label_mapping",
        "isExtraImport": true,
        "detail": "src.utils.label_mapping",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "isExtraImport": true,
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "lemmatizer",
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "isExtraImport": true,
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "numericalize",
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "isExtraImport": true,
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "src.utils.get_device",
        "description": "src.utils.get_device",
        "isExtraImport": true,
        "detail": "src.utils.get_device",
        "documentation": {}
    },
    {
        "label": "log_query_to_db",
        "importPath": "src.api.database",
        "description": "src.api.database",
        "isExtraImport": true,
        "detail": "src.api.database",
        "documentation": {}
    },
    {
        "label": "log_feedback_to_db",
        "importPath": "src.api.database",
        "description": "src.api.database",
        "isExtraImport": true,
        "detail": "src.api.database",
        "documentation": {}
    },
    {
        "label": "FeedbackModel",
        "importPath": "src.schemas.schemas",
        "description": "src.schemas.schemas",
        "isExtraImport": true,
        "detail": "src.schemas.schemas",
        "documentation": {}
    },
    {
        "label": "InferenceResponseModel",
        "importPath": "src.schemas.schemas",
        "description": "src.schemas.schemas",
        "isExtraImport": true,
        "detail": "src.schemas.schemas",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "stopwords",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "wordnet",
        "importPath": "nltk.corpus",
        "description": "nltk.corpus",
        "isExtraImport": true,
        "detail": "nltk.corpus",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "pos_tag",
        "importPath": "nltk",
        "description": "nltk",
        "isExtraImport": true,
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "WordNetLemmatizer",
        "importPath": "nltk.stem",
        "description": "nltk.stem",
        "isExtraImport": true,
        "detail": "nltk.stem",
        "documentation": {}
    },
    {
        "label": "Client",
        "importPath": "supabase",
        "description": "supabase",
        "isExtraImport": true,
        "detail": "supabase",
        "documentation": {}
    },
    {
        "label": "create_client",
        "importPath": "supabase",
        "description": "supabase",
        "isExtraImport": true,
        "detail": "supabase",
        "documentation": {}
    },
    {
        "label": "Client",
        "importPath": "supabase",
        "description": "supabase",
        "isExtraImport": true,
        "detail": "supabase",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "init",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "field_validator",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "IntentClassifier",
        "importPath": "src.models.intent_classifier",
        "description": "src.models.intent_classifier",
        "isExtraImport": true,
        "detail": "src.models.intent_classifier",
        "documentation": {}
    },
    {
        "label": "get_device",
        "importPath": "utils.get_device",
        "description": "utils.get_device",
        "isExtraImport": true,
        "detail": "utils.get_device",
        "documentation": {}
    },
    {
        "label": "log_query_to_db",
        "kind": 2,
        "importPath": "src.api.database",
        "description": "src.api.database",
        "peekOfCode": "def log_query_to_db(query_text: str, predicted_intent: str, \n                    confidence_score: float = None):\n    \"\"\"\n    Log the user query and model prediction to the Supabase database.\n    Args:\n        query_text (str): The user's query text.\n        predicted_intent (str): The predicted intent label.\n        confidence_score (float, optional): Prediction confidence score.\n    \"\"\"\n    supabase = get_supabase_client()",
        "detail": "src.api.database",
        "documentation": {}
    },
    {
        "label": "log_feedback_to_db",
        "kind": 2,
        "importPath": "src.api.database",
        "description": "src.api.database",
        "peekOfCode": "def log_feedback_to_db(query_id: int, is_correct: bool, \n                       corrected_intent: str = None):\n    \"\"\"\n    Log feedback about the prediction to the Supabase database.\n    Args:\n        query_id (int): The ID of the user query being referenced.\n        is_correct (bool): Whether the prediction was correct.\n        corrected_intent (str, optional): The corrected intent if the \n                                          prediction was incorrect.\n    \"\"\"",
        "detail": "src.api.database",
        "documentation": {}
    },
    {
        "label": "inference",
        "kind": 2,
        "importPath": "src.api.service",
        "description": "src.api.service",
        "peekOfCode": "def inference(text: str) -> InferenceResponseModel:\n    \"\"\"\n      Perform inference on input text to predict the customer's intent.\n      Args:\n          text (str): Input text from the user for which the intent is to \\\n                      be predicted.\n      Returns:\n          str: The predicted label representing the customer's intent.\n    \"\"\"\n    cleaned_text = clean_text(text)",
        "detail": "src.api.service",
        "documentation": {}
    },
    {
        "label": "submit_feedback",
        "kind": 2,
        "importPath": "src.api.service",
        "description": "src.api.service",
        "peekOfCode": "def submit_feedback(feedback_data: FeedbackModel) -> dict:\n    \"\"\"\n    Submit feedback about the prediction.\n    Args:\n        feedback_data (dict): A dictionary containing feedback information. \n        Expected keys:\n            - query_id (int): The ID of the user query.\n            - is_correct (bool): Whether the prediction was correct.\n            - corrected_intent (str, optional): The corrected intent if the \n                                                prediction was incorrect.",
        "detail": "src.api.service",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "kind": 5,
        "importPath": "src.api.service",
        "description": "src.api.service",
        "peekOfCode": "DEVICE = get_device()\nprint(f\"Using device: {DEVICE}\")\nwith open('data/vocab.json', 'r', encoding='utf-8') as f:\n    vocab = json.load(f)\nclassifier = bentoml.pytorch.get('classifier:latest').to_runner()\nsvc = bentoml.Service('classifier', runners=[classifier])\n@svc.api(input=Text(), output=JSON(pydantic_model=InferenceResponseModel))\ndef inference(text: str) -> InferenceResponseModel:\n    \"\"\"\n      Perform inference on input text to predict the customer's intent.",
        "detail": "src.api.service",
        "documentation": {}
    },
    {
        "label": "classifier",
        "kind": 5,
        "importPath": "src.api.service",
        "description": "src.api.service",
        "peekOfCode": "classifier = bentoml.pytorch.get('classifier:latest').to_runner()\nsvc = bentoml.Service('classifier', runners=[classifier])\n@svc.api(input=Text(), output=JSON(pydantic_model=InferenceResponseModel))\ndef inference(text: str) -> InferenceResponseModel:\n    \"\"\"\n      Perform inference on input text to predict the customer's intent.\n      Args:\n          text (str): Input text from the user for which the intent is to \\\n                      be predicted.\n      Returns:",
        "detail": "src.api.service",
        "documentation": {}
    },
    {
        "label": "svc",
        "kind": 5,
        "importPath": "src.api.service",
        "description": "src.api.service",
        "peekOfCode": "svc = bentoml.Service('classifier', runners=[classifier])\n@svc.api(input=Text(), output=JSON(pydantic_model=InferenceResponseModel))\ndef inference(text: str) -> InferenceResponseModel:\n    \"\"\"\n      Perform inference on input text to predict the customer's intent.\n      Args:\n          text (str): Input text from the user for which the intent is to \\\n                      be predicted.\n      Returns:\n          str: The predicted label representing the customer's intent.",
        "detail": "src.api.service",
        "documentation": {}
    },
    {
        "label": "clean_text",
        "kind": 2,
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "peekOfCode": "def clean_text(text: str) -> str:\n    \"\"\"\n    Clean text data by removing punctuation, stopwords, \\\n           and converting to lowercase.\n    Args: text (str): Input text from the user to be cleaned.\n    Returns (str): cleaned text\n    \"\"\"\n    tokens = re.sub(r\"\\{\\{.*?\\}\\}\", \"\", text)\n    tokens = word_tokenize(tokens)\n    tokens = [w.lower() for w in tokens]",
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "nltk_to_wordnet_pos",
        "kind": 2,
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "peekOfCode": "def nltk_to_wordnet_pos(nltk_tag: str) -> str:\n    \"\"\"\n    Converts an NLTK POS (part-of-speech) tag to a\n    corresponding WordNet POS tag.\n    This conversion is useful for lemmatization tasks where WordNet requires \n    specific POS tags.\n    Args:\n        nltk_tag (str): The POS tag generated by NLTK's `pos_tag` function.\n    Returns:\n        str or None: The corresponding WordNet POS tag (`wordnet.ADJ`,",
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "lemmatizer",
        "kind": 2,
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "peekOfCode": "def lemmatizer(data: str) -> list[str]:\n    \"\"\"\n    Lemmatizes the input text data by converting words to their base\n    or dictionary form using NLTK's WordNetLemmatizer.\n    The function first tokenizes the input text, assigns \n    part-of-speech (POS) tags, and then lemmatizes each word \n    based on its POS tag.\n    Args:\n        data (str): The input text to be lemmatized.\n    Returns:",
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "numericalize",
        "kind": 2,
        "importPath": "src.data_preprocessing.text_processing",
        "description": "src.data_preprocessing.text_processing",
        "peekOfCode": "def numericalize(vocab: dict[str, int], data: list[str]) -> list[list[int]]:\n    \"\"\"\n    Converts tokens into their corresponding numerical indices\n    based on a given vocabulary. If a token is not found in the vocabulary,\n    a special '<UNK>' token is used.\n    Args:\n        vocab (dict): A dictionary mapping tokens (words) to their\n                      corresponding numerical indices.\n        data (list): A list of tokens (words) to be converted into numerical\n                     indices.",
        "detail": "src.data_preprocessing.text_processing",
        "documentation": {}
    },
    {
        "label": "insert_user_query",
        "kind": 2,
        "importPath": "src.db.models",
        "description": "src.db.models",
        "peekOfCode": "def insert_user_query(supabase: Client, query_text: str, predicted_intent: str,\n                      confidence_score: float, created_at: str):\n    \"\"\"\n    Insert a new user query into the database.\n    Args:\n        supabase (Client): The Supabase client instance.\n        query_text (str): The text of the user query.\n        predicted_intent (str): The predicted intent label.\n        confidence_score (float, optional): Prediction confidence score.\n        created_at (str, optional): The timestamp when the query was \\",
        "detail": "src.db.models",
        "documentation": {}
    },
    {
        "label": "insert_feedback",
        "kind": 2,
        "importPath": "src.db.models",
        "description": "src.db.models",
        "peekOfCode": "def insert_feedback(supabase: Client, query_id: int, is_correct: bool,\n                    corrected_intent: str = None, created_at: str = None):\n    \"\"\"\n    Insert feedback into the feedback table.\n    Args:\n        supabase (Client): The Supabase client instance.\n        query_id (int): The ID of the query in the user_queries table.\n        is_correct (bool): Whether the prediction was correct.\n        corrected_intent (str, optional): Corrected intent if incorrect \\\n                                          prediction.",
        "detail": "src.db.models",
        "documentation": {}
    },
    {
        "label": "get_supabase_client",
        "kind": 2,
        "importPath": "src.db.session",
        "description": "src.db.session",
        "peekOfCode": "def get_supabase_client() -> Client:\n    \"\"\"\n    Returns the Supabase client for interacting with the database.\n    \"\"\"\n    supabase_url = os.getenv(\"SUPABASE_URL\")\n    supabase_key = os.getenv(\"SUPABASE_KEY\")\n    if not supabase_url or not supabase_key:\n        raise ValueError(\"Supabase URL and API key must be set in the env\")\n    supabase: Client = create_client(supabase_url,\n                                     supabase_key)",
        "detail": "src.db.session",
        "documentation": {}
    },
    {
        "label": "IntentClassifier",
        "kind": 6,
        "importPath": "src.models.intent_classifier",
        "description": "src.models.intent_classifier",
        "peekOfCode": "class IntentClassifier(nn.Module):\n    \"\"\"\n    A Bidirectional LSTM-based classifier for intent detection. This model \n    consists of an embedding layer, a bidirectional LSTM, and multiple \n    linear layers with GELU activation functions and dropout for \n    regularization.\n    Args:\n        config (dict): Configuration dictionary containing model parameters \n        such as:\n            - 'input_size' (int): Size of the input feature vector.",
        "detail": "src.models.intent_classifier",
        "documentation": {}
    },
    {
        "label": "FeedbackModel",
        "kind": 6,
        "importPath": "src.schemas.schemas",
        "description": "src.schemas.schemas",
        "peekOfCode": "class FeedbackModel(BaseModel):\n    query_id: int = Field(..., ge=1)\n    is_correct: bool \n    corrected_intent: Optional[str] = Field(None, max_length=100)\n    @field_validator('corrected_intent', always=True)\n    def check_corrected_intent(cls, v, values): \n        if not values['is_correct'] and not v: \n            raise ValueError('corrected_intent is required \\\n                              when is_correct is False')\n        return v ",
        "detail": "src.schemas.schemas",
        "documentation": {}
    },
    {
        "label": "InferenceResponseModel",
        "kind": 6,
        "importPath": "src.schemas.schemas",
        "description": "src.schemas.schemas",
        "peekOfCode": "class InferenceResponseModel(BaseModel):\n    predicted_intent: str\n    confidence_score: float\n    query_id: int",
        "detail": "src.schemas.schemas",
        "documentation": {}
    },
    {
        "label": "get_device",
        "kind": 2,
        "importPath": "src.utils.get_device",
        "description": "src.utils.get_device",
        "peekOfCode": "def get_device() -> str:\n    \"\"\"\n    Determines the appropriate device to use for PyTorch operations.\n    Returns:\n        str: 'cuda' if a GPU is available, 'mps' if an Apple M1/M2 GPU is \n              available, otherwise 'cpu'.\n    \"\"\"\n    if torch.cuda.is_available():\n        return 'cuda'\n    elif torch.backends.mps.is_available():",
        "detail": "src.utils.get_device",
        "documentation": {}
    },
    {
        "label": "label_mapping",
        "kind": 5,
        "importPath": "src.utils.label_mapping",
        "description": "src.utils.label_mapping",
        "peekOfCode": "label_mapping = {\n    0: 'activate_my_card',\n    1: 'age_limit',\n    2: 'apple_pay_or_google_pay',\n    3: 'atm_support',\n    4: 'automatic_top_up',\n    5: 'balance_not_updated_after_bank_transfer',\n    6: 'balance_not_updated_after_cheque_or_cash_deposit',\n    7: 'beneficiary_not_allowed',\n    8: 'cancel_transfer',",
        "detail": "src.utils.label_mapping",
        "documentation": {}
    },
    {
        "label": "load_model_and_save_to_bento",
        "kind": 2,
        "importPath": "src.utils.save_model_to_bento",
        "description": "src.utils.save_model_to_bento",
        "peekOfCode": "def load_model_and_save_to_bento(model_file: Path) -> None:\n    \"\"\"\n      Load a trained PyTorch model from a file and save it to BentoML.\n      Args:\n          model_file (Path): Path to the trained PyTorch model.\n      \"\"\"\n    lstm_model = IntentClassifier(config).to(DEVICE)\n    lstm_model.load_state_dict(torch.load(model_file,\n                                          map_location=torch.device(DEVICE),\n                                          weights_only=True))",
        "detail": "src.utils.save_model_to_bento",
        "documentation": {}
    },
    {
        "label": "DEVICE",
        "kind": 5,
        "importPath": "src.utils.save_model_to_bento",
        "description": "src.utils.save_model_to_bento",
        "peekOfCode": "DEVICE = get_device()\nprint(f\"Using device: {DEVICE}\")\nwith open('../models/model_config.yaml', 'r', encoding='utf-8') as f:\n    config = yaml.safe_load(f)\ndef load_model_and_save_to_bento(model_file: Path) -> None:\n    \"\"\"\n      Load a trained PyTorch model from a file and save it to BentoML.\n      Args:\n          model_file (Path): Path to the trained PyTorch model.\n      \"\"\"",
        "detail": "src.utils.save_model_to_bento",
        "documentation": {}
    }
]